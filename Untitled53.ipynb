{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkatamadahav/SEMICORE-ASSIMENT/blob/main/Untitled53.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  STEP 1: Install dependencies\n",
        "!pip install ultralytics opencv-python-headless\n",
        "\n",
        "#  STEP 2: Import libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from datetime import datetime\n",
        "from IPython.display import FileLink, display\n",
        "\n",
        "# STEP 3: Load YOLOv8 Pose model\n",
        "model = YOLO('yolov8n-pose.pt')  # You can use yolov8s-pose.pt for more accuracy\n",
        "\n",
        "#  STEP 4: Define fall detection logic using pose keypoints\n",
        "def is_fall_detected(keypoints):\n",
        "    try:\n",
        "        left_shoulder = keypoints[5]\n",
        "        right_shoulder = keypoints[6]\n",
        "        left_hip = keypoints[11]\n",
        "        right_hip = keypoints[12]\n",
        "\n",
        "        avg_shoulder_y = (left_shoulder[1] + right_shoulder[1]) / 2\n",
        "        avg_hip_y = (left_hip[1] + right_hip[1]) / 2\n",
        "        torso_angle = abs(avg_hip_y - avg_shoulder_y)\n",
        "\n",
        "        if torso_angle < 30:\n",
        "            return True\n",
        "    except:\n",
        "        pass\n",
        "    return False\n",
        "\n",
        "#  STEP 5: Detect fall and draw bounding box\n",
        "def detect_fall_with_box(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) or 640\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 480\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 20\n",
        "\n",
        "    out_path = \"fall_with_box_output.mp4\"\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(out_path, fourcc, fps, (width, height))\n",
        "\n",
        "    fall_triggered = False\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame = cv2.resize(frame, (width, height))\n",
        "        results = model.predict(frame, save=False, conf=0.4)\n",
        "        keypoints_list = results[0].keypoints\n",
        "        boxes = results[0].boxes\n",
        "\n",
        "        if keypoints_list is not None:\n",
        "            for i, k in enumerate(keypoints_list.xy):\n",
        "                keypoints = k.cpu().numpy()\n",
        "                if is_fall_detected(keypoints):\n",
        "                    fall_triggered = True\n",
        "                    fall_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                    print(f\"ðŸš¨ FALL DETECTED at {fall_time}\")\n",
        "\n",
        "                    # Draw bounding box around person\n",
        "                    if boxes is not None and i < len(boxes):\n",
        "                        box = boxes[i].xyxy.cpu().numpy()[0]\n",
        "                        x1, y1, x2, y2 = box.astype(int)\n",
        "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "                        cv2.putText(frame, \"FALL DETECTED!\", (x1, y1 - 10),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(\" Processing complete. Video saved with fall boxes.\")\n",
        "    display(FileLink(out_path))\n",
        "\n",
        "#  STEP 6: Run the function on your uploaded video\n",
        "detect_fall_with_box('/content/falling video.mp4')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Cn_-88swds0_",
        "outputId": "c6622245-86a9-478d-8c10-1467a8b956d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.107)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "\n",
            "0: 640x384 1 person, 149.2ms\n",
            "Speed: 4.9ms preprocess, 149.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:06\n",
            "\n",
            "0: 640x384 1 person, 163.8ms\n",
            "Speed: 3.9ms preprocess, 163.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:06\n",
            "\n",
            "0: 640x384 1 person, 141.9ms\n",
            "Speed: 2.1ms preprocess, 141.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:06\n",
            "\n",
            "0: 640x384 1 person, 145.8ms\n",
            "Speed: 4.1ms preprocess, 145.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:06\n",
            "\n",
            "0: 640x384 1 person, 140.2ms\n",
            "Speed: 4.8ms preprocess, 140.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:06\n",
            "\n",
            "0: 640x384 1 person, 148.6ms\n",
            "Speed: 4.6ms preprocess, 148.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:07\n",
            "\n",
            "0: 640x384 1 person, 148.1ms\n",
            "Speed: 4.5ms preprocess, 148.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:07\n",
            "\n",
            "0: 640x384 1 person, 147.1ms\n",
            "Speed: 4.3ms preprocess, 147.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:07\n",
            "\n",
            "0: 640x384 1 person, 145.3ms\n",
            "Speed: 4.5ms preprocess, 145.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:07\n",
            "\n",
            "0: 640x384 1 person, 155.7ms\n",
            "Speed: 4.5ms preprocess, 155.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:07\n",
            "\n",
            "0: 640x384 1 person, 148.2ms\n",
            "Speed: 4.3ms preprocess, 148.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:07\n",
            "\n",
            "0: 640x384 1 person, 200.6ms\n",
            "Speed: 5.1ms preprocess, 200.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 229.3ms\n",
            "Speed: 3.9ms preprocess, 229.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 223.4ms\n",
            "Speed: 7.6ms preprocess, 223.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 230.3ms\n",
            "Speed: 4.6ms preprocess, 230.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 237.0ms\n",
            "Speed: 4.2ms preprocess, 237.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 225.3ms\n",
            "Speed: 4.5ms preprocess, 225.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 230.2ms\n",
            "Speed: 7.6ms preprocess, 230.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 233.7ms\n",
            "Speed: 4.1ms preprocess, 233.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 231.8ms\n",
            "Speed: 4.6ms preprocess, 231.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 230.7ms\n",
            "Speed: 2.3ms preprocess, 230.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 192.9ms\n",
            "Speed: 4.7ms preprocess, 192.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 142.2ms\n",
            "Speed: 4.8ms preprocess, 142.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 141.3ms\n",
            "Speed: 4.5ms preprocess, 141.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 persons, 144.7ms\n",
            "Speed: 4.4ms preprocess, 144.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 146.1ms\n",
            "Speed: 4.4ms preprocess, 146.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 140.6ms\n",
            "Speed: 5.7ms preprocess, 140.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 140.3ms\n",
            "Speed: 4.5ms preprocess, 140.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 147.3ms\n",
            "Speed: 7.7ms preprocess, 147.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 147.2ms\n",
            "Speed: 4.2ms preprocess, 147.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 143.5ms\n",
            "Speed: 4.0ms preprocess, 143.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 145.3ms\n",
            "Speed: 4.7ms preprocess, 145.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 143.7ms\n",
            "Speed: 5.5ms preprocess, 143.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 140.2ms\n",
            "Speed: 4.4ms preprocess, 140.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 148.8ms\n",
            "Speed: 4.7ms preprocess, 148.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 151.2ms\n",
            "Speed: 2.9ms preprocess, 151.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 146.8ms\n",
            "Speed: 4.1ms preprocess, 146.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 142.4ms\n",
            "Speed: 4.4ms preprocess, 142.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 147.1ms\n",
            "Speed: 2.3ms preprocess, 147.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 141.6ms\n",
            "Speed: 3.6ms preprocess, 141.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 155.5ms\n",
            "Speed: 4.5ms preprocess, 155.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 141.3ms\n",
            "Speed: 4.3ms preprocess, 141.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 142.4ms\n",
            "Speed: 3.9ms preprocess, 142.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 144.6ms\n",
            "Speed: 4.0ms preprocess, 144.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 143.8ms\n",
            "Speed: 3.7ms preprocess, 143.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 142.7ms\n",
            "Speed: 4.2ms preprocess, 142.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 143.6ms\n",
            "Speed: 4.4ms preprocess, 143.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 151.3ms\n",
            "Speed: 3.1ms preprocess, 151.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 142.4ms\n",
            "Speed: 2.1ms preprocess, 142.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 146.7ms\n",
            "Speed: 5.0ms preprocess, 146.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 144.9ms\n",
            "Speed: 2.4ms preprocess, 144.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 164.6ms\n",
            "Speed: 4.0ms preprocess, 164.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 144.1ms\n",
            "Speed: 5.5ms preprocess, 144.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 154.9ms\n",
            "Speed: 4.7ms preprocess, 154.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 143.2ms\n",
            "Speed: 3.9ms preprocess, 143.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 143.6ms\n",
            "Speed: 4.6ms preprocess, 143.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 142.5ms\n",
            "Speed: 4.7ms preprocess, 142.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 140.2ms\n",
            "Speed: 4.0ms preprocess, 140.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 140.7ms\n",
            "Speed: 4.4ms preprocess, 140.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 151.5ms\n",
            "Speed: 4.5ms preprocess, 151.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 140.8ms\n",
            "Speed: 4.1ms preprocess, 140.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 144.3ms\n",
            "Speed: 4.1ms preprocess, 144.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 143.9ms\n",
            "Speed: 4.6ms preprocess, 143.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 144.1ms\n",
            "Speed: 4.0ms preprocess, 144.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 149.0ms\n",
            "Speed: 4.7ms preprocess, 149.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 143.1ms\n",
            "Speed: 2.5ms preprocess, 143.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 156.7ms\n",
            "Speed: 3.9ms preprocess, 156.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 145.7ms\n",
            "Speed: 5.0ms preprocess, 145.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 143.8ms\n",
            "Speed: 4.4ms preprocess, 143.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 145.3ms\n",
            "Speed: 4.1ms preprocess, 145.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 141.6ms\n",
            "Speed: 4.6ms preprocess, 141.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 140.2ms\n",
            "Speed: 4.3ms preprocess, 140.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 159.9ms\n",
            "Speed: 4.3ms preprocess, 159.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 143.7ms\n",
            "Speed: 2.2ms preprocess, 143.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 144.3ms\n",
            "Speed: 4.6ms preprocess, 144.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 147.8ms\n",
            "Speed: 4.4ms preprocess, 147.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 144.2ms\n",
            "Speed: 5.2ms preprocess, 144.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 141.0ms\n",
            "Speed: 4.4ms preprocess, 141.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 156.9ms\n",
            "Speed: 4.6ms preprocess, 156.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:19\n",
            "\n",
            "0: 640x384 1 person, 144.5ms\n",
            "Speed: 4.4ms preprocess, 144.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 142.6ms\n",
            "Speed: 6.0ms preprocess, 142.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:20\n",
            "\n",
            "0: 640x384 1 person, 142.7ms\n",
            "Speed: 4.5ms preprocess, 142.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:20\n",
            "\n",
            "0: 640x384 1 person, 141.5ms\n",
            "Speed: 4.8ms preprocess, 141.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:20\n",
            "\n",
            "0: 640x384 1 person, 213.5ms\n",
            "Speed: 4.3ms preprocess, 213.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:20\n",
            "\n",
            "0: 640x384 1 person, 238.6ms\n",
            "Speed: 4.3ms preprocess, 238.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:20\n",
            "\n",
            "0: 640x384 1 person, 224.7ms\n",
            "Speed: 3.7ms preprocess, 224.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:21\n",
            "\n",
            "0: 640x384 1 person, 226.1ms\n",
            "Speed: 2.3ms preprocess, 226.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:21\n",
            "\n",
            "0: 640x384 1 person, 217.6ms\n",
            "Speed: 4.1ms preprocess, 217.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:21\n",
            "\n",
            "0: 640x384 1 person, 239.2ms\n",
            "Speed: 2.3ms preprocess, 239.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 222.9ms\n",
            "Speed: 5.9ms preprocess, 222.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:22\n",
            "\n",
            "0: 640x384 1 person, 229.4ms\n",
            "Speed: 4.4ms preprocess, 229.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:22\n",
            "\n",
            "0: 640x384 1 person, 246.1ms\n",
            "Speed: 4.5ms preprocess, 246.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 242.0ms\n",
            "Speed: 2.9ms preprocess, 242.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 163.3ms\n",
            "Speed: 4.4ms preprocess, 163.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 144.9ms\n",
            "Speed: 4.3ms preprocess, 144.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:23\n",
            "\n",
            "0: 640x384 1 person, 138.3ms\n",
            "Speed: 2.1ms preprocess, 138.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 147.7ms\n",
            "Speed: 3.8ms preprocess, 147.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:23\n",
            "\n",
            "0: 640x384 1 person, 151.0ms\n",
            "Speed: 4.4ms preprocess, 151.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:23\n",
            "\n",
            "0: 640x384 1 person, 142.8ms\n",
            "Speed: 2.2ms preprocess, 142.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:23\n",
            "\n",
            "0: 640x384 1 person, 156.1ms\n",
            "Speed: 4.1ms preprocess, 156.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 145.3ms\n",
            "Speed: 4.4ms preprocess, 145.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:24\n",
            "\n",
            "0: 640x384 1 person, 142.1ms\n",
            "Speed: 4.6ms preprocess, 142.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:24\n",
            "\n",
            "0: 640x384 1 person, 145.0ms\n",
            "Speed: 4.0ms preprocess, 145.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:24\n",
            "\n",
            "0: 640x384 1 person, 148.9ms\n",
            "Speed: 4.6ms preprocess, 148.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:24\n",
            "\n",
            "0: 640x384 1 person, 146.2ms\n",
            "Speed: 4.5ms preprocess, 146.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:24\n",
            "\n",
            "0: 640x384 1 person, 154.6ms\n",
            "Speed: 4.6ms preprocess, 154.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:25\n",
            "\n",
            "0: 640x384 1 person, 146.0ms\n",
            "Speed: 4.3ms preprocess, 146.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:25\n",
            "\n",
            "0: 640x384 1 person, 141.1ms\n",
            "Speed: 2.3ms preprocess, 141.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:25\n",
            "\n",
            "0: 640x384 1 person, 141.4ms\n",
            "Speed: 3.9ms preprocess, 141.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:25\n",
            "\n",
            "0: 640x384 1 person, 145.7ms\n",
            "Speed: 5.1ms preprocess, 145.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:25\n",
            "\n",
            "0: 640x384 2 persons, 142.2ms\n",
            "Speed: 2.3ms preprocess, 142.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:25\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:25\n",
            "\n",
            "0: 640x384 1 person, 152.9ms\n",
            "Speed: 4.2ms preprocess, 152.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:26\n",
            "\n",
            "0: 640x384 1 person, 152.8ms\n",
            "Speed: 6.7ms preprocess, 152.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:26\n",
            "\n",
            "0: 640x384 1 person, 146.0ms\n",
            "Speed: 4.8ms preprocess, 146.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:26\n",
            "\n",
            "0: 640x384 1 person, 148.0ms\n",
            "Speed: 4.1ms preprocess, 148.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:26\n",
            "\n",
            "0: 640x384 1 person, 142.4ms\n",
            "Speed: 4.4ms preprocess, 142.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:26\n",
            "\n",
            "0: 640x384 1 person, 135.0ms\n",
            "Speed: 3.1ms preprocess, 135.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:26\n",
            "\n",
            "0: 640x384 1 person, 143.1ms\n",
            "Speed: 4.5ms preprocess, 143.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:27\n",
            "\n",
            "0: 640x384 1 person, 152.6ms\n",
            "Speed: 4.7ms preprocess, 152.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:27\n",
            "\n",
            "0: 640x384 1 person, 141.4ms\n",
            "Speed: 5.7ms preprocess, 141.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:27\n",
            "\n",
            "0: 640x384 1 person, 140.2ms\n",
            "Speed: 4.0ms preprocess, 140.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:27\n",
            "\n",
            "0: 640x384 1 person, 144.9ms\n",
            "Speed: 2.4ms preprocess, 144.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:27\n",
            "\n",
            "0: 640x384 1 person, 151.4ms\n",
            "Speed: 4.2ms preprocess, 151.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:27\n",
            "\n",
            "0: 640x384 1 person, 146.6ms\n",
            "Speed: 4.1ms preprocess, 146.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:28\n",
            "\n",
            "0: 640x384 1 person, 153.1ms\n",
            "Speed: 4.9ms preprocess, 153.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:28\n",
            "\n",
            "0: 640x384 1 person, 145.4ms\n",
            "Speed: 3.0ms preprocess, 145.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:28\n",
            "\n",
            "0: 640x384 1 person, 140.5ms\n",
            "Speed: 4.2ms preprocess, 140.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:28\n",
            "\n",
            "0: 640x384 1 person, 142.1ms\n",
            "Speed: 8.2ms preprocess, 142.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 139.8ms\n",
            "Speed: 2.9ms preprocess, 139.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ðŸš¨ FALL DETECTED at 2025-04-11 15:28:28\n",
            "\n",
            "0: 640x384 1 person, 144.4ms\n",
            "Speed: 4.0ms preprocess, 144.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "âœ… Processing complete. Video saved with fall boxes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/content/fall_with_box_output.mp4"
            ],
            "text/html": [
              "<a href='fall_with_box_output.mp4' target='_blank'>fall_with_box_output.mp4</a><br>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}